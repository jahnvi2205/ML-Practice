{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjOy-bQeUHRT"
      },
      "outputs": [],
      "source": [
        "# local csv\n",
        "import pandas as pd\n",
        "df= pd.read_csv(\"path_to_csv\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv from an URL\n",
        "url = \"https://gist.githubusercontent.com/dsternlicht/74020ebfdd91a686d71e785a79b318d4/raw/chartsninja-data-1.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5ngmGc8Y4H_",
        "outputId": "ab83e657-3977-4db9-92c1-22120b7d309e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dataset 1   Dataset 2   Dataset 3\n",
            "0        100         200         300\n",
            "1        120         240         210\n",
            "2        320         140         310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sep parameter\n",
        "# by default \",\"\n",
        "# for tsv files : \"\\t\"\n",
        "pd.read_csv(\"path_to.tsv\", sep='\\t')"
      ],
      "metadata": {
        "id": "dNw74s13Y4Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if column header not given\n",
        "pd.read_csv(\"path\", names=['sno','name','genre','votes'])"
      ],
      "metadata": {
        "id": "heuiN95CY4UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we dont want default index 0,1,2,3.. but specific col\n",
        "pd.read_csv(\"path\", index_col='enrolled_id')"
      ],
      "metadata": {
        "id": "7dGkh6p7Y4XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To make first row as header\n",
        "pd.read_csv('test.csv',header=1)"
      ],
      "metadata": {
        "id": "-koHzeYBY4eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only want specific cols from df, not all\n",
        "pd.read_csv('test.csv',usecols= ['enrolled_id','name','gender','education'])"
      ],
      "metadata": {
        "id": "YjHAEx1RY4hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skip specific cols\n",
        "pd.read_csv('test.csv', skiprows=[0,2])"
      ],
      "metadata": {
        "id": "jql0a7nWY4lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing only n no.of rows\n",
        "pd.read_csv('test.csv', nrows= 100)"
      ],
      "metadata": {
        "id": "8GEvTCO6Y4os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding paramater\n",
        "# default: UTF-8, but if we have data of emojis, lang other than english!\n",
        "#  in case of Unicode Decode Error\n",
        "pd.read_csv('test.csv', encoding= 'latin-1')"
      ],
      "metadata": {
        "id": "7ASUOTmpY4r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skip bad lines/ parser error\n",
        "pd.read_csv('test.csv', error_bad_lines= False)"
      ],
      "metadata": {
        "id": "oJGN3A3vY4ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting a col to specific data type\n",
        "pd.read_csv('test.csv', dtype={'target':int})"
      ],
      "metadata": {
        "id": "9GsizQ1tY4yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handling dates\n",
        "# by default dates are stored like object/string\n",
        "pd.read_csv('test.csv', parse_dates=['adm_date'])    #'adm_date' is col name in df"
      ],
      "metadata": {
        "id": "4jtK9mEpY41l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying a function to a col\n",
        "pd.read_csv('test.csv', converters={'team1':rename})    #'team1' is col name, 'rename' is function"
      ],
      "metadata": {
        "id": "AGd-MihsY44_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  for ex if we have values like \"-\", \"/\", \"Nil\" instead of NaN\n",
        "pd.read_csv('test.csv', na_values=['-','/'])"
      ],
      "metadata": {
        "id": "VyUqJhchY48F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading very large dataset in chunks\n",
        "dfs= pd.read_csv('test.csv', chunksize= 5000)\n",
        "\n",
        "# now we will apply every transformation in loop\n",
        "for chunks in dfs:\n",
        "  print(chunk.shape)"
      ],
      "metadata": {
        "id": "jBVh4mAaY4_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}